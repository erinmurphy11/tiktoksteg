{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1672c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4d7801b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dw_conv(\n",
    "        in_c: int, out_c: int, kernel_size: int, stride: int, padding: int\n",
    "    ):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_c,\n",
    "                in_c,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                groups=in_c,\n",
    "            ),\n",
    "            nn.BatchNorm2d(in_c),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(\n",
    "                in_c,\n",
    "                out_c,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "class HideNet(nn.Modulimport timee):\n",
    "    def get_channels(self, in_channels=6, out_channels=3, init_channels=64, max_channels=512, num_conv=6):\n",
    "        # Initialize lists\n",
    "        encoder_in = [in_channels]  # input channels for encoder\n",
    "        encoder_out = []  # output channels for encoder\n",
    "        decoder_in = []  # input channels for decoder\n",
    "        decoder_out = [max_channels]  # output channels for decoder\n",
    "\n",
    "        # Build encoder\n",
    "        for i in range(num_conv):\n",
    "            encoder_out.append(min(init_channels * 2 ** i, max_channels))\n",
    "            encoder_in.append(encoder_out[-1])\n",
    "\n",
    "        # Build decoder\n",
    "        for i in range(num_conv):\n",
    "            decoder_in.append(encoder_out[-1 - i] * 2)\n",
    "            decoder_out.append(min(init_channels * 2 ** (num_conv - i - 2), max_channels))\n",
    "\n",
    "        # Reverse the decoder lists to match the U-Net architecture\n",
    "        decoder_in\n",
    "        decoder_out\n",
    "\n",
    "        # Adjust input and output channels to match given values\n",
    "        encoder_in[0] = in_channels\n",
    "        decoder_out[-1] = out_channels\n",
    "\n",
    "        encoder_in = encoder_in[:-1]\n",
    "        decoder_out = decoder_out[1:]\n",
    "\n",
    "        return encoder_in, encoder_out, decoder_in, decoder_out\n",
    "    \n",
    "    def down_block(self, in_c: int, out_c: int, conv: nn.Module=nn.Conv2d, kernel_size: int=4, stride: int=2):\n",
    "        return nn.Sequential(\n",
    "            conv(in_c, out_c, kernel_size, stride, 1), nn.BatchNorm2d(out_c), nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def up_block(\n",
    "        self, in_c: int, out_c: int, conv: nn.Module, act=nn.ReLU, mode: str = \"nearest\"\n",
    "    ):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=mode),\n",
    "            conv(in_c, out_c, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_c: int = 6,\n",
    "        out_c: int = 3,\n",
    "        first_c: int = 64,\n",
    "        n_depthwise: int = 2,\n",
    "        upsampling_mode: str = \"nearest\",\n",
    "        n_conv: int = 6,\n",
    "        max_c: int = 512,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert 1 <= n_depthwise <= 4, \"n_depthwise must be between 1 and 4\"\n",
    "        \n",
    "        self.down_in, self.down_out, self.up_in, self.up_out = self.get_channels(\n",
    "            init_channels=first_c, \n",
    "            max_channels=max_c,\n",
    "            num_conv=n_conv,\n",
    "        )\n",
    "\n",
    "        down_layers = []\n",
    "        up_layers = []\n",
    "\n",
    "        for i in range(len(self.down_in)):\n",
    "            \n",
    "            if i < n_depthwise:\n",
    "                conv = nn.Conv2d\n",
    "            else:\n",
    "                conv = dw_conv \n",
    "                \n",
    "            down_layers.append(\n",
    "                self.down_block(self.down_in[i], self.down_out[i], conv)\n",
    "            )\n",
    "             \n",
    "            \n",
    "        for i in range(len(self.up_in) - 1):\n",
    "            \n",
    "            if i < n_depthwise:\n",
    "                conv = dw_conv\n",
    "            else:\n",
    "                conv = nn.Conv2d\n",
    "                \n",
    "            up_layers.append(\n",
    "                self.up_block(self.up_in[i], self.up_out[i], conv)\n",
    "            )\n",
    "            \n",
    "        up_layers.append(\n",
    "            self.up_block(self.up_in[-1], self.up_out[-1], nn.Conv2d, act=nn.Sigmoid)\n",
    "        )\n",
    "        \n",
    "        self.down_layers = nn.ModuleList(down_layers)\n",
    "        self.bottleneck = self.down_block(self.down_out[-1], self.down_out[-1], kernel_size=3, stride=1)\n",
    "        self.up_layers = nn.ModuleList(up_layers)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        down_out = [x]\n",
    "\n",
    "        for i in range(len(self.down_in)):\n",
    "            down_out.append(self.down_layers[i](down_out[-1]))\n",
    "\n",
    "        \n",
    "        up_out = self.bottleneck(down_out[-1])\n",
    "        up_out += down_out[-1]\n",
    "\n",
    "        for i in range(1, len(self.up_in)):\n",
    "            up_out = self.up_layers[i - 1](torch.concat([up_out, down_out[-i]], dim=1))\n",
    "            \n",
    "        up_out = self.up_layers[-1](torch.concat([up_out, down_out[1]], dim=1))\n",
    "\n",
    "        return up_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "52824d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,6,256, 128)\n",
    "net = HideNet(first_c=16, max_c=4096, n_conv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2dbc82f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 128])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "aa5f095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(128, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b93e7c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HideNet(\n",
       "  (down_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=512)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=512)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (up_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7765637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(in_c, first_c, max_c):\n",
    "    down_in = [in_c]\n",
    "    down_out = [first_c]\n",
    "    for _ in range(6):\n",
    "              # Reverse the decoder lists to match the U-Net architecture\n",
    "        decoder_in\n",
    "        decoder_out  down_in.append(min(first_c, max_c))\n",
    "        down_out.append(min(2 * first_c, max_c))\n",
    "        first_c *= 2\n",
    "        \n",
    "    up_in = [down_out[6]]\n",
    "    up_out = [] \n",
    "    \n",
    "    for i in range(6):\n",
    "        up_in.append(2 * down_out[-i - 2])\n",
    "        up_out.append(down_in[-i - 1])\n",
    "    up_out[-1] = 3 \n",
    "        \n",
    "    return down_in, down_out, up_in, up_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "855542f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6, 64, 128, 256, 512, 512, 512],\n",
       " [64, 128, 256, 512, 512, 512, 512],\n",
       " [512, 1024, 1024, 1024, 512, 256, 128],\n",
       " [512, 512, 512, 256, 128, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_channels(6,64, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, dw_1.parameters())\n",
    "sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3x3 = nn.Conv2d(128, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d513ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, conv_3x3.parameters())\n",
    "sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "403eb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(in_channels=6, out_channels=3, init_channels=64, max_channels=512, num_conv=6):\n",
    "        # Initialize lists\n",
    "        encoder_in = [in_channels]  # input channels for encoder\n",
    "        encoder_out = []  # output channels for encoder\n",
    "        decoder_in = []  # input channels for decoder\n",
    "        decoder_out = [max_channels]  # output channels for decoder\n",
    "\n",
    "        # Build encoder\n",
    "        for i in range(num_conv):\n",
    "            encoder_out.append(min(init_channels * 2 ** i, max_channels))\n",
    "            encoder_in.append(encoder_out[-1])\n",
    "\n",
    "        # Build decoder\n",
    "        for i in range(num_conv):\n",
    "            decoder_in.append(encoder_out[-1 - i] * 2)\n",
    "            decoder_out.append(min(init_channels * 2 ** (num_conv - i - 2), max_channels))\n",
    "\n",
    "        # Adjust input and output channels to match given values\n",
    "        encoder_in[0] = in_channels\n",
    "        decoder_out[-1] = out_channels\n",
    "\n",
    "        encoder_in = encoder_in[:-1]\n",
    "        decoder_out = decoder_out[1:]\n",
    "\n",
    "        return encoder_in, encoder_out, decoder_in, decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e423124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ein, eou, din, dou = get_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3843c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 64, 128, 256, 512, 512] 512 [1024, 1024, 1024, 512, 256, 128]\n",
      "[64, 128, 256, 512, 512, 512] 512 [512, 512, 256, 128, 64, 3]\n"
     ]
    }
   ],
   "source": [
    "print(ein, 512, din)\n",
    "print(eou, 512, dou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf3200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
